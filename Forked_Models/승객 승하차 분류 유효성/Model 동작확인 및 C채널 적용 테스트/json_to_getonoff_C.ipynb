{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"18sklLnjUHRUDMp7L5lvICt0k2Xfb4uqx","authorship_tag":"ABX9TyM1+AmCitlmmURvW2lm344/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1EtWKHpa5Hys","executionInfo":{"status":"ok","timestamp":1683380321159,"user_tz":-540,"elapsed":39794,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}},"outputId":"a289f3bd-d749-48ba-887b-9241f49c089a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#아래 세개 셀은 raw 데이터를 의도분석 모델 입력값으로의 변환을 위해 처음에만 쓰는 것!"],"metadata":{"id":"Yxvcvfg_4f2x"}},{"cell_type":"code","source":["#@title Utils 폴더의 data에서 찾아온 코드: __getOriginalDataList 메소드 입력 부분 약간 튜닝 \n","#from utils.data import GetOnOffData\n","\n","#__getOriginalDataList 메소드 입력 부분 약간 튜닝 \n","from __future__ import print_function\n","from __future__ import absolute_import\n","from __future__ import division\n","\n","from glob import glob\n","import os\n","from tqdm import tqdm\n","from functools import cmp_to_key\n","import json\n","import random\n","import math\n","import numpy as np\n","from datetime import datetime\n","from pytz import timezone\n","import shutil\n","from tensorflow import keras\n","import logging\n","import traceback\n","logging.basicConfig(level=logging.ERROR)\n","\n","\n","class GetOnOffData2:\n","    def __init__(self, original_data_dir, get_on_off_data_dir, dataset_dir, train_val_rate):\n","        self.original_data_list = self.__getOriginalDataList(original_data_dir)\n","        self.original_data_dir = original_data_dir\n","        self.get_on_off_data_dir = get_on_off_data_dir\n","        self.train_val_rate = train_val_rate\n","        self.original_num = 0\n","        self.get_on_json_list = []\n","        self.get_off_json_list = []\n","        self.idle_json_list = []\n","        self.get_on_num = 0\n","        self.get_off_num = 0\n","        self.idle_num = 0\n","        self.dataset_dir = dataset_dir\n","        self.train_get_on_num = 0\n","        self.val_get_on_num = 0\n","        self.test_get_on_num = 0\n","        self.train_get_off_num = 0\n","        self.val_get_off_num = 0\n","        self.test_get_off_num = 0\n","        self.train_idle_num = 0\n","        self.val_idle_num = 0\n","        self.test_idle_num = 0\n","        self.train_num = 0\n","        self.val_num = 0\n","        self.test_num = 0\n","        self.train_list = []\n","        self.val_list = []\n","        self.test_list = []\n","\n","\n","    def compare_json(self, x, y):\n","        x_index = [pos for pos, char in enumerate(x) if char == '_']\n","        x_index = x_index[-1]\n","        x_index += 1\n","        y_index = [pos for pos, char in enumerate(y) if char == '_']\n","        y_index = y_index[-1]\n","        y_index += 1\n","        x_int = int(x[x_index:-5])\n","        y_int = int(y[y_index:-5])\n","        if (x_int < y_int):\n","            return -1\n","        elif (x_int >= y_int):\n","            return 1\n","\n","    def __getOriginalDataList(self, original_data_dir):\n","        # Get Folder List\n","        folder_list = glob(original_data_dir + '/*')\n","        folder_list = [file for file in folder_list if os.path.isdir(file)]\n","        folder_list = sorted(folder_list)\n","        random.seed(0)\n","        random.shuffle(folder_list)\n","\n","        # list parameters\n","        dst = []\n","\n","        for folder in tqdm(folder_list):\n","            # Json file list\n","            json_list = os.listdir(folder)\n","            json_list = [file for file in json_list if file.endswith('.json')]\n","            json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","\n","            # Get json path\n","            tmp_list = []\n","            for json_file_name in json_list:\n","                tmp_list.append(os.path.join(folder, json_file_name))\n","\n","            dst.append(tmp_list)\n","\n","        return dst\n","\n","    def getOriginalDataLog(self):\n","        dst = ''\n","        json_count = 0\n","        for folder in self.original_data_list:\n","            for json_path in folder:\n","                json_count += 1\n","                dst += str(json_count) + '. ' + json_path + '\\n'\n","                print(str(json_count) + '. ' + json_path)\n","        self.original_num = json_count\n","\n","        return dst\n","\n","    def makeGetOnOffData(self):\n","        # Make dir\n","        get_on_dir = os.path.join(self.get_on_off_data_dir, 'get_on')\n","        get_off_dir = os.path.join(self.get_on_off_data_dir, 'get_off')\n","        idle_dir = os.path.join(self.get_on_off_data_dir, 'idle')\n","        os.makedirs(get_on_dir, exist_ok=True)\n","        os.makedirs(get_off_dir, exist_ok=True)\n","        os.makedirs(idle_dir, exist_ok=True)\n","\n","        # Count Parameters\n","        get_on_count = 0\n","        get_off_count = 0\n","        idle_count = 0\n","\n","        # file name parameters\n","        get_on_data_name = 'get_on_'\n","        get_off_data_name = 'get_off_'\n","        idle_data_name = 'idle_'\n","\n","        # Make get on off data\n","        for json_list in tqdm(self.original_data_list):\n","            # Get Passenger Data\n","            for i in range(len(json_list) - 2):\n","                # Get Json data\n","                json_path_1 = os.path.join(json_list[i])\n","                json_path_2 = os.path.join(json_list[i + 1])\n","                json_path_3 = os.path.join(json_list[i + 2])\n","                try:\n","                    with open(json_path_1, 'r') as json_file:\n","                        json_data_1 = json.load(json_file)\n","                except Exception:\n","                    raise Exception('json_path_1: ', json_path_1)\n","                try:\n","                    with open(json_path_2, 'r') as json_file:\n","                        json_data_2 = json.load(json_file)\n","                except Exception:\n","                    raise Exception('json_path_2: ', json_path_2)\n","                try:\n","                    with open(json_path_3, 'r') as json_file:\n","                        json_data_3 = json.load(json_file)\n","                except Exception:\n","                    raise Exception('json_path_3: ', json_path_3)\n","\n","                # Get Img width & height\n","                width = json_data_1['info']['width']\n","                height = json_data_1['info']['height']\n","\n","                # Get Valid data id and Append data\n","                if len(json_data_1['annotations']) != 0 and len(json_data_2['annotations']) != 0 and len(\n","                        json_data_3['annotations']) != 0:\n","                    for annotation_1 in json_data_1['annotations']:\n","                        id_1 = annotation_1['id']\n","                        for annotation_2 in json_data_2['annotations']:\n","                            id_2 = annotation_2['id']\n","                            if id_1 != id_2:\n","                                continue\n","                            else:\n","                                for annotation_3 in json_data_3['annotations']:\n","                                    id_3 = annotation_3['id']\n","                                    if id_2 != id_3:\n","                                        continue\n","                                    else:\n","                                        # Checking neck keypoint is exist\n","                                        if annotation_1['keypoints'][26] == 0 and annotation_2['keypoints'][26] == 0 and \\\n","                                                annotation_3['keypoints'][26] == 0:\n","                                            break\n","                                        # Checking head keypoint is exist\n","                                        elif annotation_1['keypoints'][29] == 0 and annotation_2['keypoints'][\n","                                            29] == 0 and annotation_3['keypoints'][29] == 0:\n","                                            break\n","                                        # Checking right shoulder keypoint is exist\n","                                        elif annotation_1['keypoints'][38] == 0 and annotation_2['keypoints'][\n","                                            38] == 0 and annotation_3['keypoints'][38] == 0:\n","                                            break\n","                                        # Checking left shoulder keypoint is exist\n","                                        elif annotation_1['keypoints'][41] == 0 and annotation_2['keypoints'][\n","                                            41] == 0 and annotation_3['keypoints'][41] == 0:\n","                                            break\n","\n","                                        # Get Data of neck keypoint\n","                                        neck_x_1 = annotation_1['keypoints'][24] / width\n","                                        neck_y_1 = annotation_1['keypoints'][25] / height\n","                                        neck_x_2 = annotation_2['keypoints'][24] / width\n","                                        neck_y_2 = annotation_2['keypoints'][25] / height\n","                                        neck_x_3 = annotation_3['keypoints'][24] / width\n","                                        neck_y_3 = annotation_3['keypoints'][25] / height\n","\n","                                        # Get Data of head keypoint\n","                                        head_x_1 = annotation_1['keypoints'][27] / width\n","                                        head_y_1 = annotation_1['keypoints'][28] / height\n","                                        head_x_2 = annotation_2['keypoints'][27] / width\n","                                        head_y_2 = annotation_2['keypoints'][28] / height\n","                                        head_x_3 = annotation_3['keypoints'][27] / width\n","                                        head_y_3 = annotation_3['keypoints'][28] / height\n","\n","                                        # Get Data of right shoulder keypoint\n","                                        r_shoulder_x_1 = annotation_1['keypoints'][36] / width\n","                                        r_shoulder_y_1 = annotation_1['keypoints'][37] / height\n","                                        r_shoulder_x_2 = annotation_2['keypoints'][36] / width\n","                                        r_shoulder_y_2 = annotation_2['keypoints'][37] / height\n","                                        r_shoulder_x_3 = annotation_3['keypoints'][36] / width\n","                                        r_shoulder_y_3 = annotation_3['keypoints'][37] / height\n","\n","                                        # Get Data of left shoulder keypoint\n","                                        l_shoulder_x_1 = annotation_1['keypoints'][39] / width\n","                                        l_shoulder_y_1 = annotation_1['keypoints'][40] / height\n","                                        l_shoulder_x_2 = annotation_2['keypoints'][39] / width\n","                                        l_shoulder_y_2 = annotation_2['keypoints'][40] / height\n","                                        l_shoulder_x_3 = annotation_3['keypoints'][39] / width\n","                                        l_shoulder_y_3 = annotation_3['keypoints'][40] / height\n","\n","                                        # Get Vector of neck->rShoulder\n","                                        vector_r_shoulder_x_1 = r_shoulder_x_1 - neck_x_1\n","                                        vector_r_shoulder_y_1 = r_shoulder_y_1 - neck_y_1\n","                                        vector_r_shoulder_x_2 = r_shoulder_x_2 - neck_x_2\n","                                        vector_r_shoulder_y_2 = r_shoulder_y_2 - neck_y_2\n","                                        vector_r_shoulder_x_3 = r_shoulder_x_3 - neck_x_3\n","                                        vector_r_shoulder_y_3 = r_shoulder_y_3 - neck_y_3\n","\n","                                        # Get Vector of neck->lShoulder\n","                                        vector_l_shoulder_x_1 = l_shoulder_x_1 - neck_x_1\n","                                        vector_l_shoulder_y_1 = l_shoulder_y_1 - neck_y_1\n","                                        vector_l_shoulder_x_2 = l_shoulder_x_2 - neck_x_2\n","                                        vector_l_shoulder_y_2 = l_shoulder_y_2 - neck_y_2\n","                                        vector_l_shoulder_x_3 = l_shoulder_x_3 - neck_x_3\n","                                        vector_l_shoulder_y_3 = l_shoulder_y_3 - neck_y_3\n","\n","                                        # Get Vector of neck->head\n","                                        vector_head_x_1 = head_x_1 - neck_x_1\n","                                        vector_head_y_1 = head_y_1 - neck_y_1\n","                                        vector_head_x_2 = head_x_2 - neck_x_2\n","                                        vector_head_y_2 = head_y_2 - neck_y_2\n","                                        vector_head_x_3 = head_x_3 - neck_x_3\n","                                        vector_head_y_3 = head_y_3 - neck_y_3\n","\n","                                        # Push Data\n","                                        data = [[0 for col in range(8)] for row in range(3)]\n","                                        data[0] = [neck_x_1, neck_y_1,\n","                                                   vector_head_x_1, vector_head_y_1,\n","                                                   vector_r_shoulder_x_1, vector_r_shoulder_y_1,\n","                                                   vector_l_shoulder_x_1, vector_l_shoulder_y_1]\n","                                        data[1] = [neck_x_2, neck_y_2,\n","                                                   vector_head_x_2, vector_head_y_2,\n","                                                   vector_r_shoulder_x_2, vector_r_shoulder_y_2,\n","                                                   vector_l_shoulder_x_2, vector_l_shoulder_y_2]\n","                                        data[2] = [neck_x_3, neck_y_3,\n","                                                   vector_head_x_3, vector_head_y_3,\n","                                                   vector_r_shoulder_x_3, vector_r_shoulder_y_3,\n","                                                   vector_l_shoulder_x_3, vector_l_shoulder_y_3]\n","\n","                                        data_dict = dict()\n","                                        data_dict['data'] = data\n","                                        data_dict['original_data'] = []\n","                                        for i in range(3):\n","                                            tmp_dict = dict()\n","                                            tmp_dict['time_step'] = i + 1\n","                                            if i == 0:\n","                                                tmp_dict['original_data_path'] = json_path_1\n","                                            elif i == 1:\n","                                                tmp_dict['original_data_path'] = json_path_2\n","                                            else:\n","                                                tmp_dict['original_data_path'] = json_path_3\n","                                            tmp_dict['id'] = annotation_3['id']\n","\n","                                            data_dict['original_data'].append(tmp_dict)\n","\n","\n","                                        # Count num of get_on get_off idle\n","                                        if annotation_3['get_on']:\n","                                            get_on_count += 1\n","                                            data_dict['label'] = 0\n","                                            json_file_name = get_on_data_name + str(get_on_count) + '.json'\n","                                            json_file_path = os.path.join(get_on_dir, json_file_name)\n","                                            if not os.path.exists(json_file_path):\n","                                                with open(json_file_path, 'w') as f:\n","                                                    json.dump(data_dict, f, indent=4)\n","\n","                                        elif annotation_3['get_off']:\n","                                            get_off_count += 1\n","                                            data_dict['label'] = 1\n","                                            json_file_name = get_off_data_name + str(get_off_count) + '.json'\n","                                            json_file_path = os.path.join(get_off_dir, json_file_name)\n","                                            if not os.path.exists(json_file_path):\n","                                                with open(json_file_path, 'w') as f:\n","                                                    json.dump(data_dict, f, indent=4)\n","\n","                                        else:\n","                                            idle_count += 1\n","                                            data_dict['label'] = 2\n","                                            json_file_name = idle_data_name + str(idle_count) + '.json'\n","                                            json_file_path = os.path.join(idle_dir, json_file_name)\n","                                            if not os.path.exists(json_file_path):\n","                                                with open(json_file_path, 'w') as f:\n","                                                    json.dump(data_dict, f, indent=4)\n","\n","                                        break\n","                            break\n","\n","        self.get_on_num = get_on_count\n","        self.get_off_num = get_off_count\n","        self.idle_num = idle_count\n","\n","    def getGetOnDataLog(self):\n","        dst = ''\n","\n","        # Get dir\n","        get_on_dir = os.path.join(self.get_on_off_data_dir, 'get_on')\n","\n","        # Get json list\n","        json_list = glob(get_on_dir + '/*')\n","        json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","        self.get_on_json_list = json_list\n","\n","        for i in range(self.get_on_num):\n","            tmp_str = str(i + 1) + '. ' + json_list[i] + '\\n'\n","            with open(json_list[i], 'r') as f:\n","                json_data = json.load(f)\n","            for original_data_dict in json_data['original_data']:\n","                time_step = original_data_dict['time_step']\n","                original_data_path = original_data_dict['original_data_path']\n","                id = original_data_dict['id']\n","                tmp_str += '\\ttime_step: {0:d}, original_data_path: {1:s}, id: {2:d}\\n'.format(time_step, original_data_path, id)\n","            dst += tmp_str\n","            print(tmp_str)\n","\n","        return dst\n","\n","    def getGetOffDataLog(self):\n","        dst = ''\n","\n","        # Get dir\n","        get_off_dir = os.path.join(self.get_on_off_data_dir, 'get_off')\n","\n","        # Get json list\n","        json_list = glob(get_off_dir + '/*')\n","        json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","        self.get_off_json_list = json_list\n","\n","        for i in range(self.get_off_num):\n","            tmp_str = str(i + 1) + '. ' + json_list[i] + '\\n'\n","            with open(json_list[i], 'r') as f:\n","                json_data = json.load(f)\n","            for original_data_dict in json_data['original_data']:\n","                time_step = original_data_dict['time_step']\n","                original_data_path = original_data_dict['original_data_path']\n","                id = original_data_dict['id']\n","                tmp_str += '\\ttime_step: {0:d}, original_data_path: {1:s}, id: {2:d}\\n'.format(time_step, original_data_path, id)\n","            dst += tmp_str\n","            print(tmp_str)\n","\n","        return dst\n","\n","    def getIdleDataLog(self):\n","        dst = ''\n","\n","        # Get dir\n","        idle_dir = os.path.join(self.get_on_off_data_dir, 'idle')\n","\n","        # Get json list\n","        json_list = glob(idle_dir + '/*')\n","        json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","        self.idle_json_list = json_list\n","\n","        for i in range(self.idle_num):\n","            tmp_str = str(i + 1) + '. ' + json_list[i] + '\\n'\n","            with open(json_list[i], 'r') as f:\n","                json_data = json.load(f)\n","            for original_data_dict in json_data['original_data']:\n","                time_step = original_data_dict['time_step']\n","                original_data_path = original_data_dict['original_data_path']\n","                id = original_data_dict['id']\n","                tmp_str += '\\ttime_step: {0:d}, original_data_path: {1:s}, id: {2:d}\\n'.format(time_step, original_data_path, id)\n","            dst += tmp_str\n","            print(tmp_str)\n","\n","        return dst\n","\n","    def divideDataByRate(self):\n","        # Get train/val/test dir and make dir\n","        train_dir = os.path.join(self.dataset_dir, 'training')\n","        val_dir = os.path.join(self.dataset_dir, 'validation')\n","        test_dir = os.path.join(self.dataset_dir, 'test')\n","        os.makedirs(train_dir, exist_ok=True)\n","        os.makedirs(val_dir, exist_ok=True)\n","        os.makedirs(test_dir, exist_ok=True)\n","\n","        # Divide data by rate\n","        self.train_get_on_num = math.ceil(self.get_on_num * self.train_val_rate[0])  # 올림\n","        self.val_get_on_num = math.floor(self.get_on_num * self.train_val_rate[1])  # 내림\n","        self.test_get_on_num = self.get_on_num - self.train_get_on_num - self.val_get_on_num\n","\n","        self.train_get_off_num = math.ceil(self.get_off_num * self.train_val_rate[0])  # 올림\n","        self.val_get_off_num = math.floor(self.get_off_num * self.train_val_rate[1])  # 내림\n","        self.test_get_off_num = self.get_off_num - self.train_get_off_num - self.val_get_off_num\n","\n","        self.train_idle_num = math.ceil(self.idle_num * self.train_val_rate[0])  # 올림\n","        self.val_idle_num = math.floor(self.idle_num * self.train_val_rate[1])  # 내림\n","        self.test_idle_num = self.idle_num - self.train_idle_num - self.val_idle_num\n","\n","        self.train_num = self.train_get_on_num + self.train_get_off_num + self.train_idle_num\n","        self.val_num = self.val_get_on_num + self.val_get_off_num + self.val_idle_num\n","        self.test_num = self.test_get_on_num + self.test_get_off_num + self.test_idle_num\n","\n","        # Get train/val/test list\n","        train_json_list = self.get_on_json_list[:self.train_get_on_num] + \\\n","                          self.get_off_json_list[:self.train_get_off_num] + \\\n","                          self.idle_json_list[:self.train_idle_num]\n","\n","        val_json_list = self.get_on_json_list[self.train_get_on_num:self.train_get_on_num + self.val_get_on_num] + \\\n","                        self.get_off_json_list[self.train_get_off_num:self.train_get_off_num + self.val_get_off_num] + \\\n","                        self.idle_json_list[self.train_idle_num:self.train_idle_num + self.val_idle_num]\n","\n","        test_json_list = self.get_on_json_list[self.train_get_on_num + self.val_get_on_num:] + \\\n","                         self.get_off_json_list[self.train_get_off_num + self.val_get_off_num:] + \\\n","                         self.idle_json_list[self.train_idle_num + self.val_idle_num:]\n","\n","        # Copy get_on/get_off/idle json files to train/validation/test dataset dir\n","        for json_path in tqdm(train_json_list):\n","            new_json_path = os.path.join(train_dir, os.path.basename(json_path))\n","            self.train_list.append(new_json_path)\n","            if not os.path.exists(new_json_path):\n","                shutil.copyfile(json_path, new_json_path)\n","        for json_path in tqdm(val_json_list):\n","            new_json_path = os.path.join(val_dir, os.path.basename(json_path))\n","            self.val_list.append(new_json_path)\n","            if not os.path.exists(new_json_path):\n","                shutil.copyfile(json_path, new_json_path)\n","        for json_path in tqdm(test_json_list):\n","            new_json_path = os.path.join(test_dir, os.path.basename(json_path))\n","            self.test_list.append(new_json_path)\n","            if not os.path.exists(new_json_path):\n","                shutil.copyfile(json_path, new_json_path)\n","\n","    def getTrainDataLog(self):\n","        dst = ''\n","        for idx in range(self.train_num):\n","            json_path = self.train_list[idx]\n","            dst += '{0:d}. {1:s}'.format(idx + 1, json_path) + '\\n'\n","            print('{0:d}. {1:s}'.format(idx + 1, json_path))\n","        return dst\n","\n","    def getValDataLog(self):\n","        dst = ''\n","        for idx in range(self.val_num):\n","            json_path = self.val_list[idx]\n","            dst += '{0:d}. {1:s}'.format(idx + 1, json_path) + '\\n'\n","            print('{0:d}. {1:s}'.format(idx + 1, json_path))\n","        return dst\n","\n","    def getTestDataLog(self):\n","        dst = ''\n","        for idx in range(self.test_num):\n","            json_path = self.test_list[idx]\n","            dst += '{0:d}. {1:s}'.format(idx + 1, json_path) + '\\n'\n","            print('{0:d}. {1:s}'.format(idx + 1, json_path))\n","        return dst\n","\n","    def generateGetOnOffData(self):\n","        # Parameters\n","        fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n","        log_str = ''\n","\n","        # Get Original Data Log str\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 원본 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        original_data_log_str = self.getOriginalDataLog()\n","        log_str += original_data_log_str + '\\n'\n","\n","        # Start making get_on, get_off, idle data\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 승하차 데이터 가공 시작'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        self.makeGetOnOffData()\n","\n","        # Get get_on data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 승차(Get On) 데이터 파일 목록 및 사용된 원본 데이터 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        get_on_log_str = self.getGetOnDataLog()\n","        log_str += get_on_log_str + '\\n'\n","\n","        # Get get_off data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 하차(Get Off) 데이터 파일 목록 및 사용된 원본 데이터 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        get_off_log_str = self.getGetOffDataLog()\n","        log_str += get_off_log_str + '\\n'\n","\n","        # Get Idle data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 무관(Idle) 데이터 파일 목록 및 사용된 원본 데이터 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        idle_log_str = self.getIdleDataLog()\n","        log_str += idle_log_str + '\\n'\n","\n","        # Start divide training, validation, test data\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Training(80%)/Validation(10%)/Test(10%) 데이터 분할 시작'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        self.divideDataByRate()\n","\n","        # Get train data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Training(80%) 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        train_log_str = self.getTrainDataLog()\n","        log_str += train_log_str + '\\n'\n","\n","        # Get val data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Validation(10%) 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        val_log_str = self.getValDataLog()\n","        log_str += val_log_str + '\\n'\n","\n","        # Get test data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Test(10%) 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        test_log_str = self.getTestDataLog()\n","        log_str += test_log_str + '\\n'\n","\n","        # summary of data\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 데이터 요약'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '원본 데이터 JSON 파일 개수: {}'.format(str(self.original_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '승차(Get On) 데이터 JSON 파일 개수: {}'.format(str(self.get_on_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '하차(Get Off) 데이터 JSON 파일 개수: {}'.format(str(self.get_off_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '무관(Idle) 데이터 JSON 파일 개수: {}'.format(str(self.idle_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = 'Training(80%) 데이터 JSON 파일 개수: {} (Get On: {}, Get Off: {}, Idle: {})'.format(\n","            self.train_num,\n","            self.train_get_on_num,\n","            self.train_get_off_num,\n","            self.train_idle_num\n","        )\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = 'Validation(10%) 데이터 JSON 파일 개수: {} (Get On: {}, Get Off: {}, Idle: {})'.format(\n","            self.val_num,\n","            self.val_get_on_num,\n","            self.val_get_off_num,\n","            self.val_idle_num\n","        )\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = 'Test(10%) 데이터 JSON 파일 개수: {} (Get On: {}, Get Off: {}, Idle: {})'.format(\n","            self.test_num,\n","            self.test_get_on_num,\n","            self.test_get_off_num,\n","            self.test_idle_num\n","        )\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 데이터 가공 완료'\n","        log_str += tmp_str + '\\n\\n'\n","        print(tmp_str)\n","\n","        return log_str"],"metadata":{"cellView":"form","id":"yFZjmmDcfVmq","executionInfo":{"status":"ok","timestamp":1683380332925,"user_tz":-540,"elapsed":3100,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["get_on_off_data = GetOnOffData2(\"/content/drive/Othercomputers/내 노트북/Forked_Models/Validation/Validation/_라벨_General_val_C/district_sample2\", \"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Apply_to_chC/getonoff/\",\"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Apply_to_chC/dataset\",(0.8, 0.1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"u04ZqQWs61HT","executionInfo":{"status":"error","timestamp":1683380324980,"user_tz":-540,"elapsed":581,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}},"outputId":"5c8d8487-ea0f-4fac-8da4-8d3386d41cfa"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a04ac54b0869>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_on_off_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetOnOffData2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/Othercomputers/내 노트북/Forked_Models/Validation/Validation/_라벨_General_val_C/district_sample2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Apply_to_chC/getonoff/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Apply_to_chC/dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'GetOnOffData2' is not defined"]}]},{"cell_type":"code","source":["get_on_off_data.generateGetOnOffData()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"5KLJDJ8FkHUo","executionInfo":{"status":"error","timestamp":1683380326140,"user_tz":-540,"elapsed":510,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}},"outputId":"701afc1a-5b0e-4050-e53b-0515ccc50c59"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-fdc4b23c13a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_on_off_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateGetOnOffData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'get_on_off_data' is not defined"]}]},{"cell_type":"markdown","source":["#A채널에 대해 학습된 모델 그대로 C채널에 적용해보기(모델 적용 첫 시도)\n","현재 경로 안에 evaluate.py, utils 폴더, dataset 폴더, output 폴더가 있어야 한다. (output 폴더는 로그를 위한 폴더로 비어있어도 됌)"],"metadata":{"id":"LqJDisGS45LD"}},{"cell_type":"code","source":["%cd \"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ed_tpUb04be2","executionInfo":{"status":"ok","timestamp":1683380421146,"user_tz":-540,"elapsed":5,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}},"outputId":"a487ceb4-9617-40a7-fd82-10a6540ff804"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC\n"]}]},{"cell_type":"code","source":["!python \"evaluate.py\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-F09tMD5mEt","executionInfo":{"status":"ok","timestamp":1683380486603,"user_tz":-540,"elapsed":63718,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}},"outputId":"e7ec3605-a890-468c-ce8e-a288ac2dd210"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-06 13:40:24.697391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","[Timestamp: 2023-05-06 22:40:29 KST+0900] 개발 환경 정보\n","OS:            Ubuntu 20.04.5 LTS \n","CPU:           Intel(R) Xeon(R) CPU @ 2.00GHz\n","GPU_0:         Tesla T4\n","Memory:        26690604 kB\n","Storage:       180.00 GiB\n","TensorFlow:    2.12.0\n","Keras:         2.12.0\n","Python:        3.10.11\n","\n","[Timestamp: 2023-05-06 22:40:30 KST+0900] Test 데이터 정보 가져오기 시작\n","[Timestamp: 2023-05-06 22:40:35 KST+0900] Test 데이터 목록\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_226.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_227.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_228.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_229.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_230.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_231.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_232.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_233.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_234.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_235.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_236.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_237.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_238.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_239.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_240.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_241.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_242.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_243.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_244.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_245.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_246.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_247.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_248.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_249.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_250.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_292.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_293.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_294.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_295.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_296.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_297.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_298.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_299.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_300.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_301.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_302.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_303.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_304.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_305.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_306.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_307.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_308.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_309.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_310.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_311.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_312.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_313.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_314.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_315.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_316.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_317.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_318.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_319.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_320.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_321.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_322.json\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_323.json\n","[Timestamp: 2023-05-06 22:40:35 KST+0900] Test 데이터 numpy 배열 정보\n","100% 57/57 [00:34<00:00,  1.67it/s]\n","Test_X Shape: (57, 3, 8)\n","Test_Y Shape: (57, 3)\n","\n","\n","2023-05-06 13:41:11.948955: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[Timestamp: 2023-05-06 22:41:12 KST+0900] 훈련 완료된 베스트 모델\n","/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/saved_models/fs_lstm_get_on_off-029.h5\n","\n","\n","[Timestamp: 2023-05-06 22:41:16 KST+0900] 모델 평가 시작\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 1. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_226.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 2. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_227.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 3. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_228.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 4. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_229.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 5. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_230.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 6. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_231.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Get On\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 7. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_232.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Get On\n","\n","[Timestamp: 2023-05-06 22:41:20 KST+0900] 8. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_233.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Get On\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 9. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_234.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Get On\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 10. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_235.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Get On\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 11. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_236.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 12. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_237.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 13. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_238.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 14. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_239.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 15. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_240.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 16. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_241.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 17. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_242.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 18. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_243.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 19. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_244.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 20. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_245.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 21. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_246.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 22. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_247.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 23. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_248.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:21 KST+0900] 24. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_249.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 25. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/get_off_250.json Test 데이터 인풋 결과\n","정답: Get Off\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 26. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_292.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 27. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_293.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 28. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_294.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 29. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_295.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 30. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_296.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 31. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_297.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 32. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_298.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 33. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_299.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 34. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_300.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 35. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_301.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 36. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_302.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 37. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_303.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 38. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_304.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 39. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_305.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:22 KST+0900] 40. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_306.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 41. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_307.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 42. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_308.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 43. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_309.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 44. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_310.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 45. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_311.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 46. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_312.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 47. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_313.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 48. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_314.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 49. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_315.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 50. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_316.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 51. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_317.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 52. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_318.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 53. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_319.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 54. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_320.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 55. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_321.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 56. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_322.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 57. /content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 동작확인 및 C채널 적용 테스트/Apply_to_chC/dataset/test/idle_323.json Test 데이터 인풋 결과\n","정답: Idle\n","예측: Idle\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 전체 Test 데이터 종합 평가 시작\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 전체 Test 데이터 종합 혼동 행렬 결과\n","                              Predicted Class\n","                              Get On         Get Off        Idle           \n","True Class     Get On         0              0              0              \n","               Get Off        5              0              20             \n","               Idle           0              0              32             \n","\n","\n","[Timestamp: 2023-05-06 22:41:23 KST+0900] 전체 Test 데이터 종합 결과\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","               Precision      Recall         F1-score       \n","Get On         0.00           0.00           0.00           \n","Get Off        0.00           0.00           0.00           \n","Idle           0.62           1.00           0.76           \n","\n","Total          0.35           0.56           0.43           \n","\n","\n","[Timestamp: 2023-05-06 22:41:24 KST+0900] 모델 평가 종료\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ggrCtzK6SsOM"},"execution_count":null,"outputs":[]}]}