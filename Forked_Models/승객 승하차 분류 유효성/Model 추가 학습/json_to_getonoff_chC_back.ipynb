{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26522,"status":"ok","timestamp":1682505835366,"user":{"displayName":"Justin Park","userId":"12032321859036831361"},"user_tz":-540},"id":"1EtWKHpa5Hys","outputId":"1cbf36b7-085f-424f-fe37-386b51792199"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Yxvcvfg_4f2x"},"source":["#아래 세개 셀은 raw 데이터를 의도분석 모델 입력값으로의 변환을 위해 처음에만 쓰는 것!"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","executionInfo":{"elapsed":3624,"status":"ok","timestamp":1682505838984,"user":{"displayName":"Justin Park","userId":"12032321859036831361"},"user_tz":-540},"id":"yFZjmmDcfVmq"},"outputs":[],"source":["#@title Utils 폴더의 data에서 찾아온 코드: __getOriginalDataList 메소드 입력 부분 약간 튜닝 \n","#from utils.data import GetOnOffData\n","\n","#__getOriginalDataList 메소드 입력 부분 약간 튜닝 \n","from __future__ import print_function\n","from __future__ import absolute_import\n","from __future__ import division\n","\n","from glob import glob\n","import os\n","from tqdm import tqdm\n","from functools import cmp_to_key\n","import json\n","import random\n","import math\n","import numpy as np\n","from datetime import datetime\n","from pytz import timezone\n","import shutil\n","from tensorflow import keras\n","import logging\n","import traceback\n","logging.basicConfig(level=logging.ERROR)\n","\n","\n","class GetOnOffData2:\n","    def __init__(self, original_data_dir, get_on_off_data_dir, dataset_dir, train_val_rate):\n","        self.original_data_list = self.__getOriginalDataList(original_data_dir)\n","        self.original_data_dir = original_data_dir\n","        self.get_on_off_data_dir = get_on_off_data_dir\n","        self.train_val_rate = train_val_rate\n","        self.original_num = 0\n","        self.get_on_json_list = []\n","        self.get_off_json_list = []\n","        self.idle_json_list = []\n","        self.get_on_num = 0\n","        self.get_off_num = 0\n","        self.idle_num = 0\n","        self.dataset_dir = dataset_dir\n","        self.train_get_on_num = 0\n","        self.val_get_on_num = 0\n","        self.test_get_on_num = 0\n","        self.train_get_off_num = 0\n","        self.val_get_off_num = 0\n","        self.test_get_off_num = 0\n","        self.train_idle_num = 0\n","        self.val_idle_num = 0\n","        self.test_idle_num = 0\n","        self.train_num = 0\n","        self.val_num = 0\n","        self.test_num = 0\n","        self.train_list = []\n","        self.val_list = []\n","        self.test_list = []\n","\n","\n","    def compare_json(self, x, y):\n","        x_index = [pos for pos, char in enumerate(x) if char == '_']\n","        x_index = x_index[-1]\n","        x_index += 1\n","        y_index = [pos for pos, char in enumerate(y) if char == '_']\n","        y_index = y_index[-1]\n","        y_index += 1\n","        x_int = int(x[x_index:-5])\n","        y_int = int(y[y_index:-5])\n","        if (x_int < y_int):\n","            return -1\n","        elif (x_int >= y_int):\n","            return 1\n","\n","    def __getOriginalDataList(self, original_data_dir):\n","        # Get Folder List\n","        folder_list = glob(original_data_dir + '/*')\n","        folder_list = [file for file in folder_list if os.path.isdir(file)]\n","        folder_list = sorted(folder_list)\n","        random.seed(0)\n","        random.shuffle(folder_list)\n","\n","        # list parameters\n","        dst = []\n","\n","        for folder in tqdm(folder_list):\n","            # Json file list\n","            json_list = os.listdir(folder)\n","            json_list = [file for file in json_list if file.endswith('.json')]\n","            json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","\n","            # Get json path\n","            tmp_list = []\n","            for json_file_name in json_list:\n","                tmp_list.append(os.path.join(folder, json_file_name))\n","\n","            dst.append(tmp_list)\n","\n","        return dst\n","\n","    def getOriginalDataLog(self):\n","        dst = ''\n","        json_count = 0\n","        for folder in self.original_data_list:\n","            for json_path in folder:\n","                json_count += 1\n","                dst += str(json_count) + '. ' + json_path + '\\n'\n","                print(str(json_count) + '. ' + json_path)\n","        self.original_num = json_count\n","\n","        return dst\n","\n","    def makeGetOnOffData(self):\n","        # Make dir\n","        get_on_dir = os.path.join(self.get_on_off_data_dir, 'get_on')\n","        get_off_dir = os.path.join(self.get_on_off_data_dir, 'get_off')\n","        idle_dir = os.path.join(self.get_on_off_data_dir, 'idle')\n","        os.makedirs(get_on_dir, exist_ok=True)\n","        os.makedirs(get_off_dir, exist_ok=True)\n","        os.makedirs(idle_dir, exist_ok=True)\n","\n","        # Count Parameters\n","        get_on_count = 0\n","        get_off_count = 0\n","        idle_count = 0\n","\n","        # file name parameters\n","        get_on_data_name = 'get_on_'\n","        get_off_data_name = 'get_off_'\n","        idle_data_name = 'idle_'\n","\n","        # Make get on off data\n","        for json_list in tqdm(self.original_data_list):\n","            # Get Passenger Data\n","            for i in range(len(json_list) - 2):\n","                # Get Json data\n","                json_path_1 = os.path.join(json_list[i])\n","                json_path_2 = os.path.join(json_list[i + 1])\n","                json_path_3 = os.path.join(json_list[i + 2])\n","                try:\n","                    with open(json_path_1, 'r') as json_file:\n","                        json_data_1 = json.load(json_file)\n","                except Exception:\n","                    raise Exception('json_path_1: ', json_path_1)\n","                try:\n","                    with open(json_path_2, 'r') as json_file:\n","                        json_data_2 = json.load(json_file)\n","                except Exception:\n","                    raise Exception('json_path_2: ', json_path_2)\n","                try:\n","                    with open(json_path_3, 'r') as json_file:\n","                        json_data_3 = json.load(json_file)\n","                except Exception:\n","                    raise Exception('json_path_3: ', json_path_3)\n","\n","                # Get Img width & height\n","                width = json_data_1['info']['width']\n","                height = json_data_1['info']['height']\n","\n","                # Get Valid data id and Append data\n","                if len(json_data_1['annotations']) != 0 and len(json_data_2['annotations']) != 0 and len(\n","                        json_data_3['annotations']) != 0:\n","                    for annotation_1 in json_data_1['annotations']:\n","                        id_1 = annotation_1['id']\n","                        for annotation_2 in json_data_2['annotations']:\n","                            id_2 = annotation_2['id']\n","                            if id_1 != id_2:\n","                                continue\n","                            else:\n","                                for annotation_3 in json_data_3['annotations']:\n","                                    id_3 = annotation_3['id']\n","                                    if id_2 != id_3:\n","                                        continue\n","                                    else:\n","                                        # Checking neck keypoint is exist\n","                                        if annotation_1['keypoints'][26] == 0 and annotation_2['keypoints'][26] == 0 and \\\n","                                                annotation_3['keypoints'][26] == 0:\n","                                            break\n","                                        # Checking head keypoint is exist\n","                                        elif annotation_1['keypoints'][29] == 0 and annotation_2['keypoints'][\n","                                            29] == 0 and annotation_3['keypoints'][29] == 0:\n","                                            break\n","                                        # Checking right shoulder keypoint is exist\n","                                        elif annotation_1['keypoints'][38] == 0 and annotation_2['keypoints'][\n","                                            38] == 0 and annotation_3['keypoints'][38] == 0:\n","                                            break\n","                                        # Checking left shoulder keypoint is exist\n","                                        elif annotation_1['keypoints'][41] == 0 and annotation_2['keypoints'][\n","                                            41] == 0 and annotation_3['keypoints'][41] == 0:\n","                                            break\n","\n","                                        # Get Data of neck keypoint\n","                                        neck_x_1 = annotation_1['keypoints'][24] / width\n","                                        neck_y_1 = annotation_1['keypoints'][25] / height\n","                                        neck_x_2 = annotation_2['keypoints'][24] / width\n","                                        neck_y_2 = annotation_2['keypoints'][25] / height\n","                                        neck_x_3 = annotation_3['keypoints'][24] / width\n","                                        neck_y_3 = annotation_3['keypoints'][25] / height\n","\n","                                        # Get Data of head keypoint\n","                                        head_x_1 = annotation_1['keypoints'][27] / width\n","                                        head_y_1 = annotation_1['keypoints'][28] / height\n","                                        head_x_2 = annotation_2['keypoints'][27] / width\n","                                        head_y_2 = annotation_2['keypoints'][28] / height\n","                                        head_x_3 = annotation_3['keypoints'][27] / width\n","                                        head_y_3 = annotation_3['keypoints'][28] / height\n","\n","                                        # Get Data of right shoulder keypoint\n","                                        r_shoulder_x_1 = annotation_1['keypoints'][36] / width\n","                                        r_shoulder_y_1 = annotation_1['keypoints'][37] / height\n","                                        r_shoulder_x_2 = annotation_2['keypoints'][36] / width\n","                                        r_shoulder_y_2 = annotation_2['keypoints'][37] / height\n","                                        r_shoulder_x_3 = annotation_3['keypoints'][36] / width\n","                                        r_shoulder_y_3 = annotation_3['keypoints'][37] / height\n","\n","                                        # Get Data of left shoulder keypoint\n","                                        l_shoulder_x_1 = annotation_1['keypoints'][39] / width\n","                                        l_shoulder_y_1 = annotation_1['keypoints'][40] / height\n","                                        l_shoulder_x_2 = annotation_2['keypoints'][39] / width\n","                                        l_shoulder_y_2 = annotation_2['keypoints'][40] / height\n","                                        l_shoulder_x_3 = annotation_3['keypoints'][39] / width\n","                                        l_shoulder_y_3 = annotation_3['keypoints'][40] / height\n","\n","                                        # Get Vector of neck->rShoulder\n","                                        vector_r_shoulder_x_1 = r_shoulder_x_1 - neck_x_1\n","                                        vector_r_shoulder_y_1 = r_shoulder_y_1 - neck_y_1\n","                                        vector_r_shoulder_x_2 = r_shoulder_x_2 - neck_x_2\n","                                        vector_r_shoulder_y_2 = r_shoulder_y_2 - neck_y_2\n","                                        vector_r_shoulder_x_3 = r_shoulder_x_3 - neck_x_3\n","                                        vector_r_shoulder_y_3 = r_shoulder_y_3 - neck_y_3\n","\n","                                        # Get Vector of neck->lShoulder\n","                                        vector_l_shoulder_x_1 = l_shoulder_x_1 - neck_x_1\n","                                        vector_l_shoulder_y_1 = l_shoulder_y_1 - neck_y_1\n","                                        vector_l_shoulder_x_2 = l_shoulder_x_2 - neck_x_2\n","                                        vector_l_shoulder_y_2 = l_shoulder_y_2 - neck_y_2\n","                                        vector_l_shoulder_x_3 = l_shoulder_x_3 - neck_x_3\n","                                        vector_l_shoulder_y_3 = l_shoulder_y_3 - neck_y_3\n","\n","                                        # Get Vector of neck->head\n","                                        vector_head_x_1 = head_x_1 - neck_x_1\n","                                        vector_head_y_1 = head_y_1 - neck_y_1\n","                                        vector_head_x_2 = head_x_2 - neck_x_2\n","                                        vector_head_y_2 = head_y_2 - neck_y_2\n","                                        vector_head_x_3 = head_x_3 - neck_x_3\n","                                        vector_head_y_3 = head_y_3 - neck_y_3\n","\n","                                        # Push Data\n","                                        data = [[0 for col in range(8)] for row in range(3)]\n","                                        data[0] = [neck_x_1, neck_y_1,\n","                                                   vector_head_x_1, vector_head_y_1,\n","                                                   vector_r_shoulder_x_1, vector_r_shoulder_y_1,\n","                                                   vector_l_shoulder_x_1, vector_l_shoulder_y_1]\n","                                        data[1] = [neck_x_2, neck_y_2,\n","                                                   vector_head_x_2, vector_head_y_2,\n","                                                   vector_r_shoulder_x_2, vector_r_shoulder_y_2,\n","                                                   vector_l_shoulder_x_2, vector_l_shoulder_y_2]\n","                                        data[2] = [neck_x_3, neck_y_3,\n","                                                   vector_head_x_3, vector_head_y_3,\n","                                                   vector_r_shoulder_x_3, vector_r_shoulder_y_3,\n","                                                   vector_l_shoulder_x_3, vector_l_shoulder_y_3]\n","\n","                                        data_dict = dict()\n","                                        data_dict['data'] = data\n","                                        data_dict['original_data'] = []\n","                                        for i in range(3):\n","                                            tmp_dict = dict()\n","                                            tmp_dict['time_step'] = i + 1\n","                                            if i == 0:\n","                                                tmp_dict['original_data_path'] = json_path_1\n","                                            elif i == 1:\n","                                                tmp_dict['original_data_path'] = json_path_2\n","                                            else:\n","                                                tmp_dict['original_data_path'] = json_path_3\n","                                            tmp_dict['id'] = annotation_3['id']\n","\n","                                            data_dict['original_data'].append(tmp_dict)\n","\n","\n","                                        # Count num of get_on get_off idle\n","                                        if annotation_3['get_on']:\n","                                            get_on_count += 1\n","                                            data_dict['label'] = 0\n","                                            json_file_name = get_on_data_name + str(get_on_count) + '.json'\n","                                            json_file_path = os.path.join(get_on_dir, json_file_name)\n","                                            if not os.path.exists(json_file_path):\n","                                                with open(json_file_path, 'w') as f:\n","                                                    json.dump(data_dict, f, indent=4)\n","\n","                                        elif annotation_3['get_off']:\n","                                            get_off_count += 1\n","                                            data_dict['label'] = 1\n","                                            json_file_name = get_off_data_name + str(get_off_count) + '.json'\n","                                            json_file_path = os.path.join(get_off_dir, json_file_name)\n","                                            if not os.path.exists(json_file_path):\n","                                                with open(json_file_path, 'w') as f:\n","                                                    json.dump(data_dict, f, indent=4)\n","\n","                                        else:\n","                                            idle_count += 1\n","                                            data_dict['label'] = 2\n","                                            json_file_name = idle_data_name + str(idle_count) + '.json'\n","                                            json_file_path = os.path.join(idle_dir, json_file_name)\n","                                            if not os.path.exists(json_file_path):\n","                                                with open(json_file_path, 'w') as f:\n","                                                    json.dump(data_dict, f, indent=4)\n","\n","                                        break\n","                            break\n","\n","        self.get_on_num = get_on_count\n","        self.get_off_num = get_off_count\n","        self.idle_num = idle_count\n","\n","    def getGetOnDataLog(self):\n","        dst = ''\n","\n","        # Get dir\n","        get_on_dir = os.path.join(self.get_on_off_data_dir, 'get_on')\n","\n","        # Get json list\n","        json_list = glob(get_on_dir + '/*')\n","        json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","        self.get_on_json_list = json_list\n","\n","        for i in range(self.get_on_num):\n","            tmp_str = str(i + 1) + '. ' + json_list[i] + '\\n'\n","            with open(json_list[i], 'r') as f:\n","                json_data = json.load(f)\n","            for original_data_dict in json_data['original_data']:\n","                time_step = original_data_dict['time_step']\n","                original_data_path = original_data_dict['original_data_path']\n","                id = original_data_dict['id']\n","                tmp_str += '\\ttime_step: {0:d}, original_data_path: {1:s}, id: {2:d}\\n'.format(time_step, original_data_path, id)\n","            dst += tmp_str\n","            print(tmp_str)\n","\n","        return dst\n","\n","    def getGetOffDataLog(self):\n","        dst = ''\n","\n","        # Get dir\n","        get_off_dir = os.path.join(self.get_on_off_data_dir, 'get_off')\n","\n","        # Get json list\n","        json_list = glob(get_off_dir + '/*')\n","        json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","        self.get_off_json_list = json_list\n","\n","        for i in range(self.get_off_num):\n","            tmp_str = str(i + 1) + '. ' + json_list[i] + '\\n'\n","            with open(json_list[i], 'r') as f:\n","                json_data = json.load(f)\n","            for original_data_dict in json_data['original_data']:\n","                time_step = original_data_dict['time_step']\n","                original_data_path = original_data_dict['original_data_path']\n","                id = original_data_dict['id']\n","                tmp_str += '\\ttime_step: {0:d}, original_data_path: {1:s}, id: {2:d}\\n'.format(time_step, original_data_path, id)\n","            dst += tmp_str\n","            print(tmp_str)\n","\n","        return dst\n","\n","    def getIdleDataLog(self):\n","        dst = ''\n","\n","        # Get dir\n","        idle_dir = os.path.join(self.get_on_off_data_dir, 'idle')\n","\n","        # Get json list\n","        json_list = glob(idle_dir + '/*')\n","        json_list = sorted(json_list, key=cmp_to_key(self.compare_json))\n","        self.idle_json_list = json_list\n","\n","        for i in range(self.idle_num):\n","            tmp_str = str(i + 1) + '. ' + json_list[i] + '\\n'\n","            with open(json_list[i], 'r') as f:\n","                json_data = json.load(f)\n","            for original_data_dict in json_data['original_data']:\n","                time_step = original_data_dict['time_step']\n","                original_data_path = original_data_dict['original_data_path']\n","                id = original_data_dict['id']\n","                tmp_str += '\\ttime_step: {0:d}, original_data_path: {1:s}, id: {2:d}\\n'.format(time_step, original_data_path, id)\n","            dst += tmp_str\n","            print(tmp_str)\n","\n","        return dst\n","\n","    def divideDataByRate(self):\n","        # Get train/val/test dir and make dir\n","        train_dir = os.path.join(self.dataset_dir, 'training')\n","        val_dir = os.path.join(self.dataset_dir, 'validation')\n","        test_dir = os.path.join(self.dataset_dir, 'test')\n","        os.makedirs(train_dir, exist_ok=True)\n","        os.makedirs(val_dir, exist_ok=True)\n","        os.makedirs(test_dir, exist_ok=True)\n","\n","        # Divide data by rate\n","        self.train_get_on_num = math.ceil(self.get_on_num * self.train_val_rate[0])  # 올림\n","        self.val_get_on_num = math.floor(self.get_on_num * self.train_val_rate[1])  # 내림\n","        self.test_get_on_num = self.get_on_num - self.train_get_on_num - self.val_get_on_num\n","\n","        self.train_get_off_num = math.ceil(self.get_off_num * self.train_val_rate[0])  # 올림\n","        self.val_get_off_num = math.floor(self.get_off_num * self.train_val_rate[1])  # 내림\n","        self.test_get_off_num = self.get_off_num - self.train_get_off_num - self.val_get_off_num\n","\n","        self.train_idle_num = math.ceil(self.idle_num * self.train_val_rate[0])  # 올림\n","        self.val_idle_num = math.floor(self.idle_num * self.train_val_rate[1])  # 내림\n","        self.test_idle_num = self.idle_num - self.train_idle_num - self.val_idle_num\n","\n","        self.train_num = self.train_get_on_num + self.train_get_off_num + self.train_idle_num\n","        self.val_num = self.val_get_on_num + self.val_get_off_num + self.val_idle_num\n","        self.test_num = self.test_get_on_num + self.test_get_off_num + self.test_idle_num\n","\n","        # Get train/val/test list\n","        train_json_list = self.get_on_json_list[:self.train_get_on_num] + \\\n","                          self.get_off_json_list[:self.train_get_off_num] + \\\n","                          self.idle_json_list[:self.train_idle_num]\n","\n","        val_json_list = self.get_on_json_list[self.train_get_on_num:self.train_get_on_num + self.val_get_on_num] + \\\n","                        self.get_off_json_list[self.train_get_off_num:self.train_get_off_num + self.val_get_off_num] + \\\n","                        self.idle_json_list[self.train_idle_num:self.train_idle_num + self.val_idle_num]\n","\n","        test_json_list = self.get_on_json_list[self.train_get_on_num + self.val_get_on_num:] + \\\n","                         self.get_off_json_list[self.train_get_off_num + self.val_get_off_num:] + \\\n","                         self.idle_json_list[self.train_idle_num + self.val_idle_num:]\n","\n","        # Copy get_on/get_off/idle json files to train/validation/test dataset dir\n","        for json_path in tqdm(train_json_list):\n","            new_json_path = os.path.join(train_dir, os.path.basename(json_path))\n","            self.train_list.append(new_json_path)\n","            if not os.path.exists(new_json_path):\n","                shutil.copyfile(json_path, new_json_path)\n","        for json_path in tqdm(val_json_list):\n","            new_json_path = os.path.join(val_dir, os.path.basename(json_path))\n","            self.val_list.append(new_json_path)\n","            if not os.path.exists(new_json_path):\n","                shutil.copyfile(json_path, new_json_path)\n","        for json_path in tqdm(test_json_list):\n","            new_json_path = os.path.join(test_dir, os.path.basename(json_path))\n","            self.test_list.append(new_json_path)\n","            if not os.path.exists(new_json_path):\n","                shutil.copyfile(json_path, new_json_path)\n","\n","    def getTrainDataLog(self):\n","        dst = ''\n","        for idx in range(self.train_num):\n","            json_path = self.train_list[idx]\n","            dst += '{0:d}. {1:s}'.format(idx + 1, json_path) + '\\n'\n","            print('{0:d}. {1:s}'.format(idx + 1, json_path))\n","        return dst\n","\n","    def getValDataLog(self):\n","        dst = ''\n","        for idx in range(self.val_num):\n","            json_path = self.val_list[idx]\n","            dst += '{0:d}. {1:s}'.format(idx + 1, json_path) + '\\n'\n","            print('{0:d}. {1:s}'.format(idx + 1, json_path))\n","        return dst\n","\n","    def getTestDataLog(self):\n","        dst = ''\n","        for idx in range(self.test_num):\n","            json_path = self.test_list[idx]\n","            dst += '{0:d}. {1:s}'.format(idx + 1, json_path) + '\\n'\n","            print('{0:d}. {1:s}'.format(idx + 1, json_path))\n","        return dst\n","\n","    def generateGetOnOffData(self):\n","        # Parameters\n","        fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n","        log_str = ''\n","\n","        # Get Original Data Log str\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 원본 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        original_data_log_str = self.getOriginalDataLog()\n","        log_str += original_data_log_str + '\\n'\n","\n","        # Start making get_on, get_off, idle data\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 승하차 데이터 가공 시작'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        self.makeGetOnOffData()\n","\n","        # Get get_on data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 승차(Get On) 데이터 파일 목록 및 사용된 원본 데이터 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        get_on_log_str = self.getGetOnDataLog()\n","        log_str += get_on_log_str + '\\n'\n","\n","        # Get get_off data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 하차(Get Off) 데이터 파일 목록 및 사용된 원본 데이터 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        get_off_log_str = self.getGetOffDataLog()\n","        log_str += get_off_log_str + '\\n'\n","\n","        # Get Idle data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 무관(Idle) 데이터 파일 목록 및 사용된 원본 데이터 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        idle_log_str = self.getIdleDataLog()\n","        log_str += idle_log_str + '\\n'\n","\n","        # Start divide training, validation, test data\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Training(80%)/Validation(10%)/Test(10%) 데이터 분할 시작'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        self.divideDataByRate()\n","\n","        # Get train data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Training(80%) 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        train_log_str = self.getTrainDataLog()\n","        log_str += train_log_str + '\\n'\n","\n","        # Get val data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Validation(10%) 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        val_log_str = self.getValDataLog()\n","        log_str += val_log_str + '\\n'\n","\n","        # Get test data list\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' Test(10%) 데이터 파일 목록'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        test_log_str = self.getTestDataLog()\n","        log_str += test_log_str + '\\n'\n","\n","        # summary of data\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 데이터 요약'\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '원본 데이터 JSON 파일 개수: {}'.format(str(self.original_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '승차(Get On) 데이터 JSON 파일 개수: {}'.format(str(self.get_on_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '하차(Get Off) 데이터 JSON 파일 개수: {}'.format(str(self.get_off_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = '무관(Idle) 데이터 JSON 파일 개수: {}'.format(str(self.idle_num))\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = 'Training(80%) 데이터 JSON 파일 개수: {} (Get On: {}, Get Off: {}, Idle: {})'.format(\n","            self.train_num,\n","            self.train_get_on_num,\n","            self.train_get_off_num,\n","            self.train_idle_num\n","        )\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = 'Validation(10%) 데이터 JSON 파일 개수: {} (Get On: {}, Get Off: {}, Idle: {})'.format(\n","            self.val_num,\n","            self.val_get_on_num,\n","            self.val_get_off_num,\n","            self.val_idle_num\n","        )\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        tmp_str = 'Test(10%) 데이터 JSON 파일 개수: {} (Get On: {}, Get Off: {}, Idle: {})'.format(\n","            self.test_num,\n","            self.test_get_on_num,\n","            self.test_get_off_num,\n","            self.test_idle_num\n","        )\n","        log_str += tmp_str + '\\n'\n","        print(tmp_str)\n","\n","        cur_time = datetime.now(timezone('Asia/Seoul')).strftime(fmt)\n","        timestamp_str = '{0:s}'.format('[Timestamp: ' + cur_time + ']')\n","        tmp_str = timestamp_str + ' 데이터 가공 완료'\n","        log_str += tmp_str + '\\n\\n'\n","        print(tmp_str)\n","\n","        return log_str"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38694,"status":"ok","timestamp":1682505910388,"user":{"displayName":"Justin Park","userId":"12032321859036831361"},"user_tz":-540},"id":"u04ZqQWs61HT","outputId":"69fe875e-3b75-412d-a55c-99465b8fc14e"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 91/91 [00:32<00:00,  2.81it/s]\n"]}],"source":["get_on_off_data = GetOnOffData2(\"/content/drive/Othercomputers/내 노트북/Forked_Models/Validation/Validation/_라벨_General_val_C/district/3. 후방 방향 이미지\", \"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 추가 학습/데이터&추가학습된 모델&유틸/getonoff/\",\"/content/drive/Othercomputers/내 노트북/Forked_Models/승객 승하차 분류 유효성/Model 추가 학습/데이터&추가학습된 모델&유틸/dataset/\",(0.8, 0.1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1yWaWUvTgwdz2SoQ6owZSitLJzWjCd_T8"},"id":"5KLJDJ8FkHUo","outputId":"6f1cb846-cbae-40ad-bdaf-27f808a493c0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["get_on_off_data.generateGetOnOffData()"]},{"cell_type":"code","source":[],"metadata":{"id":"n343JqtLg9ZG","executionInfo":{"status":"ok","timestamp":1682512206288,"user_tz":-540,"elapsed":1141,"user":{"displayName":"Justin Park","userId":"12032321859036831361"}}},"execution_count":4,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}